# Data science 5 steps design thinking

## Step 1: Data collection

Ask yourself these questions when collecting data:

Where is my data stored?  <br/>
How large is the data size?<br/>
What quantity and quality of data will I need to launch this product or service?<br/>
Who manages the data that I need to access?<br/>
When is the data updated?<br/>
Why is this data relevant for my product?<br/>

## Step 2: Data refinement

Start with these questions when refining data:

Who has insight into data dictionaries for data features?<br/>
What data requires querying, feature engineering, and pre-processing? By what techniques?<br/>
When will the required data be ready in a high quality/high quantity state to move to the next stage of the Data Science Workflow?<br/>
Where will the refined data be stored?<br/>
Why will data need to be refined?<br/>
How will the refined data be tested and validated for consistent performance?<br/>

## Step 3: Data expansion 

Apply these questions when expanding data:

Who controls data access?<br/>
What budget is available to acquire or generate more data?<br/>
When do you stop expanding data or continue to iterate with machine learning?<br/>
Where can you acquire high quality data sources?<br/>
Why are more data features needed to improve your product or solution?<br/>
How will you decide what data is most relevant to expand your data?<br/>

## Step 4: Data learning 

Ask yourself these questions during the Data Learning stage:

Who determines what benchmarks are needed for a successful model?<br/>
What machine learning frameworks and algorithms will you choose for what you will predict?<br/>
When do you decide that your modeling results are significant or ready for production?<br/>
Where will you process data learning locally or on what cloud systems?<br/>
Why does your feature request or product need machine learning?<br/>
How much compute time and compute resources are available to model the data?<br/>

## Step 5: Data maintenance

Apply these questions to better monitor your data:

Who is responsible for making changes to data models when performance changes?<br/>
What triggers, pipelines or data jobs do you implement to monitor the quality of your data in production?<br/>
When performance falls below required benchmarks, what data governance processes do you action?<br/>
Where will you commit time in your schedule on a recurring basis to monitor your data pipeline for quality control?<br/>
Why are your data modeling results reducing in quality in production?<br/>
How do you communicate data modeling results to your product managers, data engineers, and software engineers and with what frequency?<br/>

Source: https://towardsdatascience.com/data-science-design-thinking-658a4f293a1c
